<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cross-Validation Methods</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>

    <h1 id="cross-validation">Introduction to Cross-Validation Methods</h1>
    <a href="machine_learning.html" class="back-link">Back to Machine Learning Contents</a>
    <p>Cross-validation is a statistical method used to estimate the performance of machine learning models. It helps in assessing how the results of a model will generalize to an independent dataset. There are several methods of cross-validation, each with its own advantages and disadvantages.</p>
    
    <h2>Types of Cross-Validation Methods</h2>
    
    <h3>1. K-Fold Cross-Validation</h3>
    <p>In K-Fold Cross-Validation, the original sample is randomly partitioned into K equal-sized subsamples. Of the K subsamples, a single subsample is retained as the validation data for testing the model, and the remaining K-1 subsamples are used as training data. The cross-validation process is then repeated K times, with each of the K subsamples used exactly once as the validation data.</p>
    
    <h3>2. Stratified K-Fold Cross-Validation</h3>
    <p>Stratified K-Fold Cross-Validation is a variation of K-Fold Cross-Validation where the folds are made by preserving the percentage of samples for each class. This is particularly useful for imbalanced datasets.</p>
    
    <h3>3. Leave-One-Out Cross-Validation (LOOCV)</h3>
    <p>Leave-One-Out Cross-Validation (LOOCV) is a special case of K-Fold Cross-Validation where K is equal to the number of observations in the dataset. This means that each fold is used exactly once as a validation while the remaining observations form the training set. LOOCV can be computationally expensive for large datasets but is useful for small datasets.</p>
    
    <h3>4. Leave-P-Out Cross-Validation</h3>
    <p>In Leave-P-Out Cross-Validation, P observations are used as the validation set and the remaining observations as the training set. This process is repeated for all possible combinations of P observations. Like LOOCV, this method can also be computationally expensive for large datasets.</p>
    
    <h3>5. Time Series Cross-Validation</h3>
    <p>Time Series Cross-Validation is used for time series data where the order of data points matters. In this method, the training set consists of observations up to a certain time point, and the test set consists of observations after that time point. The process is repeated by moving the time point forward.</p>
    
    <h2>Example of K-Fold and LOOCV in Python</h2>
    <p>Here is a simple example demonstrating K-Fold Cross-Validation and Leave-One-Out Cross-Validation using Python and the <code>scikit-learn</code> library:</p>
    <pre><code>import numpy as np
from sklearn.model_selection import KFold, LeaveOneOut, cross_val_score
from sklearn.linear_model import LinearRegression

# Example data
X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
y = np.dot(X, np.array([1, 2])) + 3

# Create a linear regression model
model = LinearRegression()

# K-Fold Cross-Validation
kf = KFold(n_splits=2)
kf_scores = cross_val_score(model, X, y, cv=kf)
print("K-Fold Cross-Validation Scores:", kf_scores)

# Leave-One-Out Cross-Validation
loo = LeaveOneOut()
loo_scores = cross_val_score(model, X, y, cv=loo)
print("Leave-One-Out Cross-Validation Scores:", loo_scores)</code></pre>
    
    <h2>Conclusion</h2>
    <p>Cross-validation is a critical tool in assessing the performance and generalizability of machine learning models. Different cross-validation methods can be applied based on the size and nature of the dataset, as well as the computational resources available. Choosing the appropriate cross-validation method can help in building robust and reliable models.</p>
    
    <a href="machine_learning.html" class="back-link">Back to Machine Learning Contents</a>

</body>
</html>
